# -*- coding: utf-8 -*-
"""Fetching Data From an API

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cu2iJjfVhcUNcqyREn4Yg7Ihs9Ejw8Wf
"""

import pandas as pd
import requests # making HTTP requests

response = requests.get('https://api.themoviedb.org/3/movie/top_rated?api_key=8265bd1679663a7ea12ac168da84d2e8&language=en-US&page=1') # Sending a GET request

df = pd.DataFrame(response.json()['results'])[['id','title','overview','release_date','popularity','vote_average','vote_count']]

df.head()

df = pd.DataFrame()

df

import pandas as pd
import requests

# Create an empty DataFrame to store the results
df_list = []  # Using a list to collect DataFrames for better performance

for i in range(1, 429):
    response = requests.get(
        f'https://api.themoviedb.org/3/movie/top_rated?api_key=8265bd1679663a7ea12ac168da84d2e8&language=en-US&page={i}'
    )
    if response.status_code == 200:  # Ensure the request is successful
        temp_df = pd.DataFrame(response.json()['results'])[
            ['id', 'title', 'overview', 'release_date', 'popularity', 'vote_average', 'vote_count']
        ]
        df_list.append(temp_df)  # Append each DataFrame to the list
    else:
        print(f"Failed to fetch data for page {i}: {response.status_code}")

# Combine all DataFrames at once using pd.concat
df = pd.concat(df_list, ignore_index=True)

# Display the first few rows
print(df.head())

df

df.shape

df.to_csv('movies.csv')

